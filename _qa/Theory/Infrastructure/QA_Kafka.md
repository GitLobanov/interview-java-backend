## QA
#### Как выбирается партиция в Kafka?

- [[../../../_inforage/Kafka/Storage/Kafka распределение партиций]]

#### Как Kafka определяет, что консумер живой

Консумер посылает периодические `poll` запросы и `heartbeat` сигналы для проверки своего состояния в группе консумеров, поддерживая сессию.

#### Как реализуется общение Kafka to Kafka, какие есть нюансы?

Общение Kafka to Kafka обычно реализуется через продюсеров и консумеров, где:
-  Продюсер отправляет сообщения в один Kafka-кластер.
-  Консьюмер в другом Kafka-кластере подписывается на нужные топики и обрабатывает сообщения.

Нюансы:
- Репликация между кластерами: Для передачи данных между кластерами Kafka часто используют MirrorMaker — специальный инструмент для репликации топиков между кластерами Kafka.
- Балансировка нагрузки: При увеличении числа партиций можно увеличить количество консумеров для параллельной обработки сообщений.
- Гарантии доставки: Возможны три варианта доставки: at-most-once, at-least-once, и exactly-once, в зависимости от требований к целостности данных.

#### Что будет если у нас несколько консюмеров и продюсеров, как они будут взаимодействовать

- Продюсеры отправляют сообщения в топики Kafka. Продюсеры могут работать параллельно и писать в одну или несколько партиций.
- Консумеры объединяются в consumer group, и каждая партиция топика назначается одному консумеру из группы. Если партиций больше, чем консумеров, то некоторые консумеры будут обрабатывать несколько партиций.
- Балансировка нагрузки: Kafka автоматически распределяет партиции между консумерами в группе, чтобы избежать дублирования обработки сообщений.
- Обработка сообщений: Если консумеров больше, чем партиций, некоторые консумеры будут простаивать.

#### Какие гарантии доставки есть в Kafka?

![[../../../_inforage/Kafka/Storage/Kafka Consumer#Семантики доставки#Кратко]]


#### Как обеспечить exactly-once семантику?


#### Когда происходит ребалансировка? Какие есть виды?

- **Eager Rebalancing**: In traditional Kafka rebalancing, when a member joins or leaves the consumer group, the group coordinator triggers a full rebalance. This leads to all consumers in the group stopping and restarting, causing latency spikes and inefficiency.
- **Cooperative Rebalancing**: This new approach, introduced in Kafka 2.4, allows consumers to continue consuming messages during the rebalance, while only transferring the partition assignments that need to change. It minimizes downtime and allows for smoother transitions when changes happen in the consumer group.


#### Как гарантировать порядок сообщений?

- [Kafka partition strategy—Tutorial & strategies](https://www.redpanda.com/guides/kafka-tutorial-kafka-partition-strategy)
- [Стратегии отправки сообщений в партиции](../../../_inforage/Kafka/Storage/Kafka%20Producer.md#Стратегии%20отправки%20сообщений%20в%20партиции)
- [Стратегии распределения консюмеров](../../../_inforage/Kafka/Storage/Kafka%20Consumer.md#Стратегии%20распределения%20консюмеров)

###### С каким брокером сообщений ты работал? Расскажи про kafka и rebbitmq и их различия?

###### Как отправить одно сообщение нескольким слушателям в rabbitmq?


###### Как отправить одно сообщение нескольким слушателям в kafka?

###### Для чего нужны партиции в kafka?


###### Дублируются в партиции сообщения?

###### Conumers group зачем нужны

###### Offsets зачем нужны

###### Что будет если присвоить сообщениям одинаковые id

###### Что будет, 3 партициии и 4 консьюмера?


###### Как распределяются сообщения внутри топиков, партиций?

1. **Без ключа (Round-Robin):**
    - Если ключ не указан, сообщения равномерно распределяются по всем доступным разделам.
    - Пример:
        ```
        Partition 0: Msg1, Msg4
        Partition 1: Msg2, Msg5
        Partition 2: Msg3, Msg6
        ```
        
2. **С использованием ключа (Key-based partitioning):**
    - Если сообщение содержит ключ, Kafka использует хеширование ключа для выбора раздела:
        ```
        partition = hash(key) % number_of_partitions
        ```
    - Это гарантирует, что все сообщения с одинаковым ключом будут попадать в один раздел.
        
3. **Кастомный алгоритм (Custom Partitioning):**
    - Производитель может реализовать собственную логику распределения сообщений по разделам, например, на основе содержимого сообщения.
4. **Пример с ключами:**
    - Топик с 3 разделами:
        ```
        Key: "user1" -> Partition 0
        Key: "user2" -> Partition 1
        Key: "user3" -> Partition 2
        ```
5. **Manual/Sticky Partitioning:**
    - Производитель может явно указать, в какой раздел отправить сообщение.
###### Мы можем легко увеличивать количество партиций? Уменьшить?


###### Что такое Zookeeper?

###### Возьмем Kafka, у нас 4 операции update, create, delete, get. Мы спроектируем очередь следующим образом: один топик, все туда складываем, там все по ключу (в качестве ключа будем передавать операцию). Написали консьюмера, получаем все сообщения в одном консьюмере. Дальше нужно что-то с этим сделать. Т.е. если это пришло для create, то мы должны отправить на соответствующий сервис на создание и т.д. с другими операциями. Как бы ты это реализовал? (в зависимости от ключа)

###### Какие проблемы решают брокеры сообщений?

###### Какие существуют паттерны работы с очередями?

- **Point-to-Point (P2P)**: Один продюсер, один потребитель. Сообщение читается одним потребителем и удаляется из очереди.
- **Publish-Subscribe (Pub/Sub)**: Один продюсер отправляет сообщение нескольким подписчикам через обменники.
- **Work Queue**: Несколько потребителей обрабатывают сообщения из одной очереди, распределяя нагрузку.
- **Dead Letter Queue (DLQ)**: Очередь для сообщений, которые не удалось обработать.
- **Priority Queue**: Сообщения обрабатываются в зависимости от их приоритета.

###### Основные компоненты Kafka?

- _Producer_ (Производитель) — отправляет данные в Kafka.
- _Consumer_ (Потребитель) — получает данные из Kafka.
- _Event_ (Событие) - это основная единица данных, которая передается и хранится в системе. Состоит из ключа (опционально), значения, заголовков и метки времени.
- _Topics_ (Топики) — логическая сущность, разделяющая данные на каналы. Каждый топик хранит сообщения в порядке их поступления.
- _Partitions_ (Партиции) — подмножества топиков, которые разделяют данные для их распределенного хранения и параллельной обработки. Партиции дают возможность хранить данные на разных серверах.
- _Broker_ (Брокер) — сервер, ответственный за хранение данных в Kafka.
- _ZooKeeper_ — служит для управления и координации брокеров, поддерживает метаданные системы. Однако в новых версиях Kafka можно использовать KRaft (Kafka Raft), который заменяет ZooKeeper.
- _Consumer Group_ (Группа потребителей) — объединение консьюмеров, которые параллельно обрабатывают данные одного топика. Каждый консьюмер в группе обрабатывает разные партиции топика, что улучшает параллельность и производительность.

###### Как гарантировать в Kafka идемпотентность, чтобы не было задвоений и потерь сообщений?

1. **Включение идемпотентности у производителя:**
    - Включите параметр `enable.idempotence` в конфигурации продюсера:
        ```java
        Properties props = new Properties();
        props.put("enable.idempotence", "true");
        ```
    - Это позволяет Kafka отслеживать дубликаты сообщений с использованием уникального идентификатора производителя (**Producer ID**) и последовательного номера сообщения (**Sequence Number**).
2. **Ретрай на уровне продюсера:**
    - Используйте конфигурацию `retries` для автоматической повторной отправки сообщений в случае временных ошибок:
        ```java
        props.put("retries", Integer.MAX_VALUE);
        ```
3. **Репликация:**
    - Убедитесь, что уровень подтверждений (`acks`) установлен в `"all"`, чтобы гарантировать запись сообщения во все реплики:
        ```java
        props.put("acks", "all");
        ```
4. **Idempotent Producer:**
    - При включенной идемпотентности Kafka автоматически предотвращает дублирование сообщений на уровне брокера.

######  Acknowledgment в Kafka

**Типы acks:**
1. **acks = 0:**
    - Производитель не ждет подтверждения.
    - Самая быстрая, но ненадежная стратегия (возможна потеря сообщений).
2. **acks = 1:**
    - Производитель ждет подтверждения от лидера раздела.
    - Сообщение считается доставленным, если лидер записал его в лог.
    - Возможна потеря сообщений, если лидер сбоит до синхронизации реплик.
3. **acks = all (или -1):**
    - Производитель ждет подтверждения от всех реплик, включая лидера.
    - Максимальная надежность: сообщения не теряются, если хотя бы одна реплика доступна.
    - Подходит для критичных данных.
**Пример настройки acks:**
```java
Properties props = new Properties();
props.put("acks", "all");
```
###### Вопросы про отключение одного из консьюмеров. Что происходит в ситуации, когда отваливается консьюмер? Кто контроллирует перераспределение нагрузки?


###### Есть система которую нужно горизонтально маштабировать n-ое количество раз. Как сделать так чтобы каждая инсталляция вычитывала из Кафки информацию полностью всю?


###### Как взаимодействовали с Kafka? Есть ли опыт в подключении и настройки Kafka?


###### У нас есть n интстансов консюмеров, которые подключены к одному топику, продюссер у нас 1. Как сделать чтобы каждый из консюмеров, вычитывал независимо каждое сообщение? Количество консюмеров мы заранее не знаем

###### В каких форматах хранятся данные в кафке, помимо JSON?

###### Какой паттерн используется для прослушки топика Kafka в приложение?


###### Как вычитывать из топика бачами по периодам


###### Паттерны гарантии доставки

###### Проблемы в паттерне transactional outbox с кафкой
###### Что такое “Стримить в Кафку”

###### В чем особенность Kafka Listener

###### Какая дефолтная гарантия доставки сообщений в kafka?

######  Как писать в конкретную партицию?

###### Как правильно обработать ошибку?

- Вызвать метод у CompletableFuture?

###### Разница между Kafka и RabbitMQ

- **Модели сообщений**
    - _Kafka_. Сообщения не удаляются после доставки
    - _RabbitMQ_. Сообщения удаляются после доставки
- **Обработка сообщений**
    - _Kafka_. Потребители сами запрашивают сообщения из топиков, читая их по мере необходимости
    - _RabbitMQ_. Сообщения пушатся к потребителям из очереди, когда те готовы их принять (следовательно сервер может лечь, если данных данных слишком много)
- **Производительность**
    - _Kafka_ быстрее и производительнее чем _RabbitMQ_ (за счет partition-ов + горизонтальное масштабирование)

###### Что даст увеличение количества консьюмеров?

1. **Параллельная обработка:**
    - Увеличение числа потребителей в группе позволяет обрабатывать данные параллельно, так как каждый потребитель обрабатывает свои разделы (partitions).
    - Если количество потребителей меньше или равно количеству разделов, это приводит к увеличению производительности.
2. **Ограничения:**
    - Один раздел может быть назначен только одному потребителю в группе.
    - Если количество потребителей превышает количество разделов, “лишние” потребители не будут получать данные, так как разделы не могут быть разделены между несколькими потребителями.
3. **Пример:**
    - Топик с 4 разделами:
        - Если в группе 2 потребителя, то каждый будет обрабатывать 2 раздела.
        - Если в группе 4 потребителя, каждый получит 1 раздел.
        - Если в группе 5 потребителей, один из них останется без работы.

###### На что делится partition?

Раздел (partition) **не делится** дальше, он является минимальной единицей хранения и обработки данных в Kafka. Однако внутри раздела данные организуются следующим образом:
1. **Лог записи:**
    - Сообщения в разделе хранятся в лог-файле и имеют уникальные смещения (**offsets**), которые используются для идентификации и упорядочивания сообщений.
2. **Реплики:**
    - Каждый раздел может иметь одну или несколько копий (реплик) для обеспечения отказоустойчивости.
3. **Лидер и фолловеры:**
    - Один брокер управляет разделом как лидер, а остальные брокеры хранят реплики и выступают как фолловеры.

#### Если каждый консюмер находиться в отденой группе, у каждого свой offset, когда сообщения будут доступны для послед. удаления?

Каждая consumer-группа хранит **собственный offset** (позицию чтения) в топике. Однако **удаление сообщений не зависит от consumer-групп** – оно зависит **только от настроек топика**.

**Консюмер получит ошибку `OFFSET_OUT_OF_RANGE`**, если попытается прочитать удаленные offset'ы.

1. **Увеличить `log.retention.ms`** (например, на 30 дней).
2. **Использовать `retention.bytes`** (если важно хранить больше данных, а не по времени).
3. **Настроить `min.cleanable.dirty.ratio`** (чтобы реже чистились сегменты).
4. **Использовать **`offsets.retention.minutes`** (по умолчанию `7 дней`) – это время, сколько Kafka хранит offset'ы для неактивных consumer-групп.

#### Если консюмер не был активен 8 дней, а потом пришло сообщение

`offsets.retention.minutes`** (по умолчанию `7 дней`) – это время, сколько Kafka хранит offset'ы для неактивных consumer-групп. Если консюмер не активен дольше, его offset может быть удален, и он начнет читать с `latest` или `earliest` (в зависимости от `auto.offset.reset`).

#### Что такое кафка Streams?

Библиотека для обработки потоков данных в Kafka (аналогично стримам в Java).

## Resources

- [RedPanda Understanding Apache Kafka](https://www.redpanda.com/guides/kafka-tutorial-kafka-partition-strategy)
- [Using Spring for Apache Kafka](https://docs.spring.io/spring-kafka/reference/kafka.html)
- 