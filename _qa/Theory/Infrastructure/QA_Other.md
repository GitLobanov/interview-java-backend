#### Что такое сборщик проекта? Для каких целей он нужен?

Система сборки программного обеспечения (ПО) — это специализированный инструмент, обеспечивающий автоматизацию процесса компиляции исходного кода в исполняемые артефакты, проведения тестирования, управления зависимостями и генерации финального продукта, готового для развёртывания. Данный процесс включает в себя несколько этапов, таких как компиляция исходного кода в машинные или промежуточные байт-коды, связывание с необходимыми библиотеками, проверка на соответствие функциональности через тесты и, в конечном итоге, упаковка готового программного продукта в удобный для распространения формат (например, исполняемый файл или контейнер).

Современные системы сборки не ограничиваются только автоматизацией компиляции. Они представляют собой мощные экосистемы, которые также включают управление зависимостями, тестирование кода, генерацию документации, запуск статических анализаторов, развёртывание в тестовые и производственные среды, интеграцию с системами контроля версий и многими другими этапами, составляющими жизненный цикл разработки программного обеспечения.

Что сборщик умеет делать

1. Компилировать проект
2. Чистить все ненужное
3. Управления зависимостями. Обращаться к библиотекам, используемым в проекте
4. Запускать приложение
5. Запускать тесты

### Опишите структуру pom файла

`pom.xml` — это основной конфигурационный файл для проектов Maven. Его структура включает следующие основные элементы:

- **`<project>`**: корневой элемент.
- **`<modelVersion>`**: версия модели POM.
- **`<groupId>`**: уникальный идентификатор группы проекта.
- **`<artifactId>`**: уникальный идентификатор артефакта.
- **`<version>`**: версия проекта.
- **`<packaging>`**: тип пакета (например, JAR, WAR).
- **`<dependencies>`**: секция, в которой указываются зависимости проекта.
- **`<build>`**: секция, описывающая процесс сборки, включая плагины и цели.
- **`<repositories>`**: список репозиториев для загрузки зависимостей.
- **`<pluginRepositories>`**: репозитории для плагинов.

### Какие есть преимущества у Gradle над Maven?

Более быстрая сборка по сравнению с Maven. Это преимущество особенно заметно при работе с большими проектами или в условиях, когда сборка выполняется многократно (например, при CI/CD). Важную роль здесь играют:

- Инкрементальные сборки: Gradle пересобирает только те части проекта, которые были изменены, в то время как Maven зачастую пересобирает проект целиком.
- Кэширование сборок: Кэширование результатов задач в Gradle позволяет повторно использовать результаты, что минимизирует повторное выполнение задач, если их входные данные не изменились.
- Параллелизация: Gradle может выполнять задачи параллельно, что значительно сокращает общее время выполнения.

Пример настройки параллельных сборок:

```
org.gradle.parallel = true
```

Мощные инструменты оптимизации. Gradle предоставляет разработчикам множество встроенных инструментов для оптимизации процесса сборки. Вот несколько примеров:

- Гибкость в определении задач: Gradle позволяет создавать кастомные задачи с использованием логики на Groovy или Kotlin, что делает его более мощным и гибким в сценариях сложных процессов сборки. Например, вы можете настроить выполнение задач только в определённых условиях или создать новые задачи, специфичные для вашего проекта.
- Гибкая работа с зависимостями: В отличие от Maven, Gradle предоставляет более продвинутые возможности управления зависимостями, такие как строгий контроль версий, конфликты зависимостей и удобные средства для их разрешения.
- Интеграция с различными инструментами и платформами: Gradle легко интегрируется с инструментами тестирования, развертывания и другими платформами, благодаря поддержке плагинов и API. Плагины могут быть легко написаны или подключены для решения специфических задач, что делает Gradle гибким для различных проектов.

### Что такое наследование в Maven? Какие параметры наследования? Что лучше?

Наследование в Maven позволяет одному проекту наследовать настройки другого, что упрощает конфигурацию множества проектов. Параметры наследования включают:

- **`<parent>`**: ссылка на родительский POM.
- **`<dependencyManagement>`**: управление зависимостями в родительском POM.
- **`<version>`**: версия артефакта может быть задана в родительском POM.

Что лучше зависит от конкретного проекта, но обычно Maven предпочтителен для крупных корпоративных проектов, где важна консистентность и стандартизация, в то время как Gradle более гибкий и подходит для разнообразных сценариев.

### Структура типичного проекта на Gradle

Типичная структура проекта на Gradle:

```
/project-root
    ├── build.gradle           (корневой файл конфигурации)
    ├── settings.gradle        (подключение подпроектов)
    ├── /module1
        ├── build.gradle      (файл конфигурации для module1)
        ├── src/
            ├── main/
                ├── java/    (код для module1)
                ├── resources/ 
            ├── test/
                ├── java/    (тесты для module1)
                ├── resources/
    ├── /module2
        ├── build.gradle      (файл конфигурации для module2)
        ├── src/
            ├── main/
                ├── java/    (код для module2)
                ├── resources/
            ├── test/
                ├── java/    (тесты для module2)
                ├── resources/
    └── gradle/                (настройки для Gradle)
```

settings.gradle

- `rootProject.name` — задает имя корневого проекта.
- `include` — указывает подмодули проекта. Это означает, что `module1`, `module2`, и `module3` являются подмодулями корневого проекта и должны быть расположены в соответствующих каталогах.


### Как Gradle использует кэширование для того чтобы ускорить сборку проекта?

Gradle использует кэширование для ускорения сборки, сохраняя результаты сборки и данные зависимостей между сборками. Когда Gradle обнаруживает, что исходные файлы не изменились с предыдущей сборки, он может использовать ранее сгенерированные артефакты и результаты, избегая повторной работы. Это называется кэшированием и инкрементальной сборкой.

Да, в Gradle действительно используется кэширование не только для артефактов, но и для различных промежуточных файлов и данных, которые ускоряют инкрементальную сборку. Давай разберемся, что именно может кэшироваться в процессе работы Gradle.

1. Кэширование артефактов и зависимостей:  
    Это один из основных видов кэширования. Когда Gradle загружает зависимости (например, библиотеки из Maven репозиториев), они сохраняются в локальном кэше (обычно в папке `~/.gradle/caches`), чтобы не загружать их заново при каждой сборке.
2. Кэширование промежуточных файлов и результатов задач:  
    В Gradle для ускорения инкрементальной сборки также кэшируются результаты выполнения задач. Это значит, что если ты не изменил входные данные задачи (например, исходный код или конфигурацию), то Gradle может пропустить выполнение этой задачи в следующий раз, использовав результаты из кэша. Пример:
    - Исходный код: Если ты изменил только один исходный файл, Gradle пересоберет только тот модуль или задачу, который зависит от этого файла, а не всю сборку.
    - Ресурсы и конфигурации: Аналогично, если ресурсы или конфигурации не изменились, они также могут быть взяты из кэша.
3. Кэширование выводов задач:  
    Gradle кэширует не только артефакты, но и результат выполнения задач. Например, если ты строишь проект, то результат компиляции может быть сохранен в кэше. В следующий раз, если исходные файлы не изменились, Gradle использует этот результат из кэша, чтобы не компилировать код заново.
4. Кэширование информации о зависимости между задачами:  
    Gradle строит граф зависимостей между задачами и кэширует информацию о том, какие задачи зависимы друг от друга. Это помогает понять, какие задачи нужно выполнить, а какие можно пропустить.
5. Данные инкрементальной сборки:  
    В процессе инкрементальной сборки Gradle отслеживает, какие файлы были изменены, и пересобирает только те части проекта, которые были затронуты изменениями. Для этого Gradle использует информацию о том, что было собрано ранее, и кэширует эту информацию.

Пример с инкрементальной сборкой:  
Предположим, у тебя есть проект с несколькими модулями. Ты изменяешь только один файл в одном модуле. В следующий раз при сборке Gradle видит, что этот файл был изменен, и только пересобирает этот модуль. Все остальные модули и задачи, которые не затронуты изменениями, будут взяты из кэша, и их не нужно будет собирать заново.

Это кэширование, например, может происходить в директории `~/.gradle/buildOutputCleanup`, где хранятся данные о том, какие файлы были собраны и когда они были собраны.

Таким образом, Gradle активно использует кэширование, чтобы минимизировать время сборки за счет повторного использования ранее собранных артефактов, промежуточных файлов и результатов выполнения задач.

#### Как создать свою таску? На каком языке ее можно реализовывать?

Для создания собственной задачи в Gradle нужно добавить ее в файл `build.gradle`. Например, на языке Groovy:

```groovy
task myTask {
    doLast {
        println 'Hello, this is my custom task!'
    }
}
```

Задачи в Gradle пишутся на Groovy или Kotlin (для Kotlin DSL).

#### Git Flow, Github Flow, Trunk Based Development как работают модели ветвления?

[GitFlow, GithubFlow, Trunk based development. Выбираем оптимальную модель ветвления](https://timeweb.cloud/tutorials/microservices/kak-vybrat-optimalnuyu-model-vetvleniya)

- Git Flow: это модель, которая включает использование нескольких веток для различных целей: `master` (основная стабильная ветка), `develop` (разработка), `feature` (фичи), `release` (релизы), и `hotfix` (горячие исправления). Эта модель подходит для крупных проектов с планированием релизов.

Основные ветки GitFlow

- master/main: содержит тестированный, стабильный код, который может быть выложен на прод.
- develop: основная ветка для разработки, содержит актуальный, но не релизный код.
- feature: ветки для разработки новых функциональностей, которые впоследствии сливаются с develop.
- release: ветка для подготовки новых релизов, отделяется от `develop`, затем сливается с master и develop.
- hotfix: ветки для быстрого исправления ошибок в продакшен-версиях, сливаются с master и develop.

- GitHub Flow: более простая модель для проектов, которые часто выпускаются и требуют быстрой доставки изменений. Основной рабочий процесс включает работу с одной основной веткой (`main` или `master`), создавая ветки для фич и пулл-реквесты для интеграции.
- Trunk Based Development: модель, при которой разработчики всегда работают в основной ветке (trunk), с коротким жизненным циклом для веток фич и частыми интеграциями. Подходит для непрерывной интеграции и непрерывной доставки.

Это значит, что с данным подходом не нужно быть  привязанным к релизным циклам, аналогично GithubFlow, но отличие заключается именно в том, что в Trunk Based Development работа ведется непосредственно в основной ветке, с минимумом долгосрочных фича-веток. Это обеспечивает постоянное обновление продукта и возможность быстро реагировать на изменения без значительных задержек. Когда фича будет полностью реализована, на ветку перед слиянием можно повесить метку, которая скажет другим разработчикам, что фича готова:

Для управления рисками и обеспечения контроля над новыми функциями, которые могут быть не полностью готовы к использованию всеми пользователями, в Trunk Based Development активно используются feature flags. Feature flags позволяют разработчикам включать или отключать функциональность без необходимости делать новые деплои. Таким образом, можно управлять доступом к новым функциям, проводить A/B тестирование, постепенное внедрение и сбор обратной связи от пользователей в реальных условиях эксплуатации.

| **Критерий**          | **GitFlow**                                                                                        | **GitHub Flow**                                               | **Trunk Based Development (TBD)**                                                       |
| --------------------- | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| **Размер команды**    | Лучше подходит для больших команд                                                                  | Хорошо работает для команд любого размера                     | Идеален для средних и больших команд                                                    |
| **Релизные циклы**    | Длинные, с предварительными релизами (staging)                                                     | Короткие, релизы могут быть частыми и быстрыми                | Очень короткие, непрерывные релизы                                                      |
| **Сложность фичей**   | Поддерживает сложные фичи, требующие длительной разработки                                         | Лучше подходит для простых или средней сложности фич          | Подходит для простых и модернизированных фич                                            |
| **Зависимости фичей** | Управление зависимостями через разные ветки                                                        | Фичи должны быть относительно независимы                      | Фичи должны быть независимы или использовать feature flags для управления зависимостями |
| **Опытность команды** | Подходит для команд с любым уровнем опыта, но требует хорошей документации процесса внутри команды | Простое управление, подходит для команд с любым уровнем опыта | Требует дисциплины CI/CD и комфорта с непрерывной интеграцией                           |

#### Fast-forward и recursive merge

- Fast-forward merge: это тип слияния, который происходит, когда ветка, с которой сливаются изменения, не имеет собственных коммитов, и слияние может быть выполнено без конфликтов (просто перемещается указатель на последний коммит).
- Recursive merge: происходит, когда необходимо объединить два разветвленных дерева коммитов, и Git пытается решить конфликты, создав дополнительный коммит слияния.

- Rebase переносит изменения с одной ветки поверх другой, изменяя историю коммитов, перемещая их "вперед" в контексте ветки, в которую вы их накладываете. Это может изменять хеши коммитов, создавая новый набор коммитов.
- В Fast-forward merge история не изменяется, и просто двигается указатель ветки, в которую сливаются изменения, на новый коммит. Нет изменений в самом содержимом истории — только указатель ветки.

#### Как можно скопировать коммит сделанный в одной ветке в другую?

Можно использовать команду `git cherry-pick` для копирования коммита из одной ветки в другую. Например:

`git checkout target-branch git cherry-pick <commit-hash>`

оманде `git cherry-pick` можно назначить ряд опций.

```undefined
-edit
```

Если назначить команде опцию `-edit`, перед выборочным применением Git предложит указать сообщение коммита.

```css
--no-commit
```

При использовании опции `--no-commit` выборочное применение не создаст новый коммит, а переместит содержимое целевого коммита в рабочий каталог текущей ветки.

```css
--signoff
```

При выборочном применении опция `--signoff` добавляет строку с подписью в конце сообщения коммита.

Кроме этого, команде `git cherry-pick` можно назначить различные опции, определяющие стратегию слияния. Подробную информацию об этих опциях см. в документации по [стратегиям слияния Git](https://www.atlassian.com/ru/git/tutorials/using-branches/merge-strategy).

Команде git cherry-pick также можно назначить опции для разрешения конфликтов слияния, такие как `--abort, --continue` и `--quit`. Подробную информацию об этих опциях можно найти на страницах команд [git merge](https://www.atlassian.com/ru/git/tutorials/using-branches/git-merge) и [git rebase](https://www.atlassian.com/ru/git/tutorials/rewriting-history/git-rebase).
#### Что такое BDD

Основной идеей данной методологии является совмещение в процессе разработки чисто технических интересов и интересов бизнеса, позволяя тем самым управляющему персоналу и программистам говорить на одном языке. Для общения между этими группами персонала используется предметно-ориентированный язык, основу которого представляют конструкции из естественного языка, понятные неспециалисту, обычно выражающие поведение программного продукта и ожидаемые результаты.

1. Концепция BDD - есть расширение методологии TDD.
2. Тесты пишутся на предметно-ориентированном языке, их легко изменять.
3. Тесты становятся доступны как программистам и тестировщикам, так и менеджерам.
4. Тесты не зависят от целевого языка программирования. Миграция на другой язык сильно упрощается.

Таким образом, суть состоит в том, что изначально на основе определенных лингвистических шаблонов составляются **верхнеуровневые сценарии**, описывающие вероятное поведение системы. После этого разрабатывается функциональность. Ожидается, что после завершения разработки предопределенные тестовые сценарии станут успешно выполняться.

#### Что такое язык Gherkin

Итак, Gherkin - человеко-читаемый язык для описания поведения системы, который использует отступы для задания структуры документа. Каждая строчка начинается с одного из ключевых слов и описывает один из шагов.  
  
1. Структура документа задается отступами.
2. Каждый шаг начинается с ключевого слова.
3. Новый шаг - новая строка.

Пример истории  

```
История: Короткое описание требуемого функционала  → Заголовок
 
   В роли определенного участника взаимодействия с системой
   Чтобы достичь определенных целей                → Описание
   Я хочу получить определенную пользу
 
   Сценарий: Какая-то определенная бизнес-ситуация → Сценарий
      Допустим какое-то условие
         И ещё одно условие
      Когда предпринимается какое-то действие участником
         И им делается ещё что-то
         И вдобавок он совершил что-то ещё
      Тогда получается какой-то проверяемый результат
         И что-то ещё случается, что мы можем проверить
```

Использование Gherkin удобно по ряду причин:  

1. Сценарии, определяющие поведение системы, описываются в простой форме и могут быть понятны всем участникам проекта.
2. Файлы, содержащие в себе спецификации, одновременно являются и исполняемыми автотестами.
3. Тестовая документация и программный код автотестов хранятся в одном проекте и неотделимы друг от друга.
4. Наличие словаря доступных шагов допускает вариантивность сценариев и позволяет тестировщикам составлять новые автотесты, не обращаясь к программному коду.

#### Какие ключевые секции присутствуют в конфигурационном файле .git-ci.yml

Основные секции файла [gitlab-ci.yml](https://hmarketing.ru/blog/git/fayl-gitlab-ci-yml/)

- **`stages`**: определяет последовательность этапов (например, `build`, `test`, `deploy`).
- **`jobs`**: задания, которые выполняются на каждом этапе.
- `tags` назначение Runner'а на основе тегов
- **`scripts`**: команды, которые выполняются в рамках каждого задания.
- **`artifacts`**: артефакты, которые сохраняются после выполнения задания.
- **`services`**: сервисы, которые запускаются для тестов или сборки (например, базы данных).
- **`variables`**: переменные окружения для использования в конфигурации.
- `include` повторное использование конфигураций
- `cache` дает возможность сохранить в кэше
- `image` образ контейнера
- `only и except` условия для выполнения или пропуска задач
- `rules` условия для выполнения или пропуска задач
- `environment` управляет развертыванием задач в определенные среды

Эти секции позволяют настроить автоматические процессы сборки, тестирования и деплоя для CI/CD.
#### Что такое Swagger ? []

Swagger — это набор инструментов для проектирования, документирования и тестирования RESTful API. Он позволяет описывать API в стандартизированном формате (OpenAPI) и автоматически генерировать документацию, клиентские библиотеки и даже mock-серверы.

#### Аннотации в java для Swagger

`@OpenAPIDefinition` – задает метаинформацию API (версия, описание, контакты и т.д.).

```java
@OpenAPIDefinition(
    info = @Info(
        title = "User API",
        version = "1.0",
        description = "API для управления пользователями",
        contact = @Contact(name = "Dev Team", email = "dev@example.com")
    )
)
```

Для описания контроллеров и эндпоинтов

`@Tag` – добавляет тег к контроллеру (группирует операции в Swagger UI).

```java
@Tag(name = "User Management", description = "Операции с пользователями")
@RestController
public class UserController { ... }
```

`@Operation` – описывает конкретный метод (эндпоинт).

```java
@Operation(
    summary = "Получить пользователя по ID",
    description = "Возвращает пользователя с указанным идентификатором"
)
@GetMapping("/users/{id}")
public User getUser(@PathVariable Long id) { ... }
```

`@ApiResponses` / `@ApiResponse` – документирует возможные HTTP-ответы.

```java
@ApiResponses({
    @ApiResponse(responseCode = "200", description = "Пользователь найден"),
    @ApiResponse(responseCode = "404", description = "Пользователь не найден")
})
```

`@Schema` – описывает поля DTO-классов.
`@Parameter` – документирует параметры метода (Path, Query, Header и т.д.).

#### Что такое Open API ? [X]

OpenAPI (ранее Swagger Specification) – это стандартный формат описания RESTful API в виде YAML/JSON-файла. Он позволяет:

- Унифицировать документацию.
- Автоматизировать генерацию кода.
- Интегрироваться с инструментами тестирования (Postman, ReadyAPI).

```yaml
openapi: 3.0.0
info:
  title: Sample API
  version: 1.0.0
paths:
  /users:
    get:
      summary: Get all users
      responses:
        '200':
          description: OK
```

#### Расскажите, какие преимущества у Api first подхода ?

API-first – это методология, при которой API проектируется до написания кода приложения.

1. Согласованность – все команды (frontend, backend, мобильные разработчики) работают с единой спецификацией.
2. Раннее тестирование – mock-серверы позволяют тестировать клиенты до реализации бэкенда.
3. Автоматизация – генерация кода и документации экономит время.
4. Масштабируемость – легче добавлять новые сервисы и микросервисы.
5. Поддержка множества клиентов – один API может использоваться в web, мобильных приложениях и партнерских интеграциях.

#### Что такое Liquibase и flyway ?

Это инструменты для управления миграциями базы данных (Database Migration). Они позволяют применять и откатывать изменения схемы БД в контролируемом порядке.

- Liquibase:
    - Использует XML, YAML, JSON или SQL-скрипты.
    - Поддерживает транзакции, зависимости между миграциями.
    - Есть возможность предварительной проверки изменений (diff).
- Flyway:
    - Работает только с SQL-скриптами (или Java-кодом).
    - Проще в настройке, но менее гибкий.
    - Использует нумерованные версии файлов (например, `V1__Create_table.sql`).

#### Должны ли мы использовать вставки в таблицы при написании миграций ? 

- Можно:
    - Для начального заполнения справочников (например, роли пользователей `admin`, `user`).
    - В тестовых средах.
- Нельзя:
    - Вставлять тестовые данные, которые могут нарушить работу prod-окружения.
    - Использовать жестко закодированные ID (может вызвать конфликты).
Лучшие практики:
- Использовать `INSERT IGNORE` или `ON CONFLICT DO NOTHING` для избежания дубликатов.
- Выносить данные в отдельные миграции или seed-скрипты.

#### Как откатить изменения, сделанные с помощью миграции БД ?

Flyway:
- Команда `flyway undo` (только в платной версии Enterprise).
- В бесплатной версии – создавать новые миграции для отката вручную.
Liquibase:
- Автоматический откат с помощью `rollback` (если в миграции определены шаги отката).

```xml
<changeSet id="1" author="me">
  <createTable tableName="users">
    <!-- columns -->
  </createTable>
  <rollback>
    <dropTable tableName="users"/>
  </rollback>
</changeSet>
```

Затем: `liquibase rollback <версия>`.

Команда `rollbackCount` позволяет откатить определённое количество выполненных changeSet. Например, если вы хотите откатить только последнее изменение, достаточно указать `rollbackCount 1`:

```shell
./liquibase rollbackCount 1
```

Откат rollback tag

Этот подход позволяет откатить все изменения, сделанные после указанного тега, включая саму запись о создании тега. Например, если нужно откатиться до версии `v.2.0.0`, команда будет выглядеть так:

```bash
./liquibase rollback v.2.0.0
```

### Resources

- [Миграции схемы базы данных с Liquibase](https://struchkov.dev/blog/ru/get-started-liquibase/)
- 